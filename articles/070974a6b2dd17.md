---
title: "Whisperã¨ChatGPTã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ã‚’è¡Œã„è¦ç´„ã—ã¦ã¿ãŸ"
emoji: "ğŸ¦"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: [OpenAI, WhisperAPI, ChatGPT, Node.js]
published: true
---
ã©ã†ã‚‚@yanteraã§ã™ã€‚

ä»Šå›ã¯ChatGPTã¨Whisperã‚’ä½¿ã£ã¦æ–‡å­—èµ·ã“ã—ã‚’ã—ãŸã®ã§ã€ãã®å¿˜å‚™éŒ²ã«ãªã‚Šã¾ã™ã€‚
githubã§å…¬é–‹ã‚‚ã—ã¦ã„ã‚‹ã®ã§èˆˆå‘³ãŒã‚ã‚‹æ–¹ã¯æ˜¯éè¦‹ã¦ãã ã•ã„ã€‚
https://github.com/yantera/whisper-and-chatgpt

NodeJS 18.16.0ã‚’ä½¿ã£ã¦ã„ã¾ã™ã€‚

# å®Ÿè¡Œæ‰‹é †
1. 10åˆ†ä»¥ä¸Šã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€10åˆ†æ¯ã«ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²ã‚’è¡Œã†ã€‚
2. åˆ†å‰²ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯Prifixã‚’ä»˜ã‘ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­ã‹ã‚‰Whisper APIã§æ–‡å­—èµ·ã“ã—ã‚’è¡Œã†ã€‚
3. æ–‡å­—èµ·ã“ã—ã‚’è¡Œã£ãŸçµæœã‚’ä¸€ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ã¨ã‚ã‚‹ã€‚

# å®Ÿè¡Œç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒãƒ³ãƒ‰ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚ä½¿ã„æ–¹ã¯[github](https://github.com/yantera/whisper-and-chatgpt)ã‚’è¦‹ã¦ãã ã•ã„ã€‚
```typescript:index.ts
#!/usr/bin/env node
import { Command } from "commander";
import { summaryLongTextApp } from "./summaryLongText";
import { transcribeAudioApp } from "./transcribeAudio";
import { splitVoiceMemoApp } from "./splitVoiceMemo";

function main() {
  const program = new Command();
  program
    .description("Learn ChatGPT API By Example");
  program
    .command("split-voice-memo <inputFileName> <outputDirName>")
    .action(async(inputFileName, outputDirName) => {
      await splitVoiceMemoApp(inputFileName, outputDirName);
    });
  program
    .command("transcribe-audio <dirName> <maxFileCount>")
    .description("transcribe audio files")
    .action(async(dirName, maxFileCount) => {
      await transcribeAudioApp(dirName, maxFileCount);
    });
  program
    .command("summary-long-text <file>")
    .description("summarize a long text file")
    .option("-d, --debug", "debug mode", false)
    .action(async (file, options) => {
      await summaryLongTextApp(file, { debug: options.debug });
    });
  program.parse(process.argv);
}

main();
```
# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²
ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã§ã¯éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚
mp3ãŒä¸€ç•ªæ‰±ã„ã‚„ã™ãã†ã ã£ãŸã®ã§ã€ffmpegã§ã™ã¹ã¦ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’mp3ã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚

```typescript:splitVoiceMemo.ts
import { exec } from "child_process";
import * as fs from "fs";
import path from "path";

// ffmpegã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°
function runFFmpegCommand(command: string): Promise<string> {
  return new Promise((resolve, reject) => {
    exec(command, (error, stdout, stderr) => {
      if (error) {
        reject(error);
      } else {
        resolve(stdout.trim());
      }
    });
  });
}

// å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’mp3ã«å¤‰æ›ã™ã‚‹é–¢æ•°
function convertToMp3(inputFile: string): Promise<string> {
  const mp3InputFile: string = path.join(path.dirname(inputFile), `${path.basename(inputFile, path.extname(inputFile))}.mp3`);
  const command: string = `ffmpeg -i ${inputFile} -acodec libmp3lame -q:a 2 "${mp3InputFile}"`;
  console.log('Created mp3');
  return runFFmpegCommand(command).then(() => mp3InputFile);
}

// å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’å–å¾—ã™ã‚‹é–¢æ•°
function getInputFileDuration(mp3InputFile: string): Promise<number> {
  const command: string = `ffprobe -i "${mp3InputFile}" -show_entries format=duration -v quiet -of json | jq -r '.format.duration | tonumber'`;
  return runFFmpegCommand(command).then(output => {
    const duration: number = parseFloat(output);

    if (isNaN(duration)) {
      throw new Error('Invalid duration: ' + output);
    }

    return duration;
  });
}

async function splitMp3File(mp3File: string, dirName: string): Promise<void> {
  try {
    // åˆ†å‰²ã™ã‚‹æ™‚é–“é–“éš”ï¼ˆç§’å˜ä½ï¼‰
    const interval: number = 600; // 10åˆ† = 10 * 60ç§’

    // å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
    const outputFilePrefix: string = "output_";
    const outputDirPath: string = `/app/voices/outputs/${dirName}`;

    // å¤‰æ›ã—ãŸmp3ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤§ãã•ã‚’å–å¾—
    const duration: number = await getInputFileDuration(mp3File);

    // åˆ†å‰²ã™ã‚‹å›æ•°ã‚’è¨ˆç®—ã™ã‚‹
    const numSegments: number = Math.ceil(duration / interval);

    // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    if (!fs.existsSync(outputDirPath)) {
      fs.mkdirSync(outputDirPath);
    }

    // åˆ†å‰²ã™ã‚‹ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆã—ã¦å®Ÿè¡Œã™ã‚‹
    for (let i = 1; i <= numSegments; i++) {
      const start: number = (i - 1) * interval;
      const end: number = Math.min(i * interval, duration);
      const outputFile: string = `${outputDirPath}/${outputFilePrefix}${i}.mp3`;
      const command: string = `ffmpeg -i "${mp3File}" -ss ${start} -to ${end} -c copy "${outputFile}"`;
      console.log(`Splitting segment ${i} (${start} - ${end}) to ${outputFile}`);
      await runFFmpegCommand(command);
    }
  } catch (error) {
    console.error(error);
  }
}

async function removeMp3File(mp3File: string): Promise<void> {
  try {
    console.log('Removing mp3');
    const removeMp3FileCommand: string = `rm -f "${mp3File}"`;
    await runFFmpegCommand(removeMp3FileCommand);
  } catch (error) {
    console.error(error);
  }
}

export async function splitVoiceMemoApp(inputFileName: string, dirName: string): Promise<void> {
  try {
    // å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’mp3ã«å¤‰æ›ã™ã‚‹
    const originFile: string = `/app/voices/origin/${inputFileName}`;
    const mp3File: string = await convertToMp3(originFile);

    // mp3ã‚’ãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²ã™ã‚‹
    await splitMp3File(mp3File, dirName);

    // ä½œæˆã—ãŸmp3ã‚’å‰Šé™¤
    await removeMp3File(mp3File);
  } catch (error) {
    console.error(error);
  }
}
```

# Whisper APIã‚’ç”¨ã„ã¦ã®æ–‡å­—èµ·ã“ã—
å‰è¿°ã§ä½œæˆã—ãŸoutput_xxx.mp3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…ƒã«WhisperAPIã‚’ä½¿ç”¨ã—ã¦æ–‡å­—èµ·ã“ã—ã‚’è¡Œã„ã¾ã™ã€‚
dirNameã¨ä½œæˆã—ãŸmp3ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’è¨­å®šã™ã‚‹ã¨ä¸‹è¨˜ã®ã‚³ãƒ¼ãƒ‰ã§å®Ÿè¡Œå‡ºæ¥ã¾ã™ã€‚
```typescript:transcribeAudio.ts
import { Configuration, OpenAIApi } from "openai";
import fs from "fs";

const configuration = new Configuration({
  organization: process.env.OPENAI_API_ORGANIZATION_ID,
  apiKey: process.env.OPENAI_API_KEY,
});

export async function transcribeAudioApp(dirName: string, maxFileCount: number): Promise<void> {
  const stream = fs.createWriteStream(`texts/origin/${dirName}.txt`);
  const openai = new OpenAIApi(configuration);

  for (let i = 1; i <= maxFileCount; i++) {
    const resp = await openai.createTranscription(
      fs.createReadStream(`voices/outputs/${dirName}/output_${i}.mp3`) as any,
      "whisper-1",
      undefined,
      "text"
    );
    console.log(resp.data);
    stream.write(resp.data);
  }
  stream.end("\n");
  // ã‚¨ãƒ©ãƒ¼å‡¦ç†
  stream.on("error", (err: Error) => {
    if (err) console.log(err.message);
  });
}
```

ã“ã“ã¾ã§ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã¨ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¦ã„ã‚‹ã¯ãšã§ã™ã€‚ã“ã®æ–‡å­—èµ·ã“ã—ã—ãŸçµæœã‚’å…ƒã«ChatGPT APIã§è¦ç´„ã—ã¦ã„ãã¾ã™ã€‚

# ChatGPTã‚’ç”¨ã„ã¦æ–‡å­—èµ·ã“ã—ã‚’ã—ãŸå†…å®¹ã‚’è¦ç´„
ä¸‹è¨˜ã®ã‚³ãƒ¼ãƒ‰ã¯NewsPicksã•ã‚“ã®[ã“ã¡ã‚‰](https://github.com/newspicks/learn-chatgpt-api/blob/main/src/summaryLongText.ts)ã‚’å…ƒã«ã—ã¦ãŠã‚Šã¾ã™ã€‚
å¤‰æ›´ç‚¹ã¨ã—ã¦ã¯ãƒ•ã‚¡ã‚¤ãƒ«æ•°ãŒå¤šã„å ´åˆã€tooManyRequestsã¨ã„ã†ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹ã®ã§sleepã‚’è¿½åŠ ã—ã¦ã„ã¾ã™ã€‚

```typescript:summaryLongText.ts
import * as fs from "fs/promises";
import { Configuration, OpenAIApi, ChatCompletionRequestMessage } from "openai";

import { chunkString } from "./util";

const maxInputLength = 3500;
const maxSummaryLength = 400;
const maxRecursion = 10; // å¿µã®ãŸã‚

function summaryPrompt(text: string): string {
    return `ä»¥ä¸‹ã®æ–‡ç« ã‚’200å­—ç¨‹åº¦ã®æ—¥æœ¬èªã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n${text}`;
}

interface Config {
    debug: boolean;
}

function sleep(ms: number){
  return new Promise((resolve) => setTimeout(resolve, ms));
}

export async function summaryLongTextApp(file: string, { debug }: Config): Promise<void> {
    const rawText = await fs.readFile(file, "utf-8");
    const summaryText = await getSummary(rawText, debug);
    console.log(`# Final summary\n${summaryText}`);
}

async function getSummary(text: string, debug: boolean, level: number = 1): Promise<string> {
    const configuration = new Configuration({ apiKey: process.env.OPENAI_API_KEY });
    const openai = new OpenAIApi(configuration);

    // å†å¸°çš„è¦ç´„
    if (text.length <= maxSummaryLength || level > maxRecursion) {
        return text;
    }

    const textChunks = chunkString(text, maxInputLength);
    const summaryChunks = await Promise.all(textChunks.map(
      async (chunk, index) => {
        await sleep(1000*index);
        const messages: ChatCompletionRequestMessage[] = [
          {role: "user", content: summaryPrompt(chunk)}
        ]
        const completion = await openai.createCompletion({
          model: "text-davinci-003",
          prompt: summaryPrompt(chunk),
          max_tokens: maxSummaryLength,
          temperature: 0,
        });
        const chunkSummary = completion.data.choices[0].text || "";
        if (debug) {
          console.log(`# Summary level ${level}, chunk ${index}\n${chunkSummary}\n\n`);
        }
        return chunkSummary;
      }
    ));
    const joinedSummary = summaryChunks.join("\n");
    if (debug) {
        console.log(`# Summary level ${level}\n${joinedSummary}\n\n`);
    }
    return getSummary(joinedSummary, debug, level + 1);
}
```

# æ‰€æ„Ÿ
è‡³ã‚‰ãªã„ç‚¹ã¯ã¾ã ã¾ã ã‚ã‚‹ã¨æ€ã„ã¾ã™ãŒã€ä¸€æ—¦ã“ã‚Œã§è¦ä»¶ã‚’æº€ãŸã™ã“ã¨ãŒå‡ºæ¥ã¾ã—ãŸã€‚
å€‹äººçš„ã«ã¯å†å¸°çš„ã«ChatGPT APIã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è¡Œã£ãŸå ´åˆã€ç²¾åº¦ãŒã©ã‚“ã©ã‚“è½ã¡ã‚‹ã®ãŒæ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹ãªã¨æ€ã„ã¾ã—ãŸã€‚
ç²¾åº¦ãŒ80%ç¨‹åº¦ã¨ä»®å®šã—ã¦ã€çµæœã«å¯¾ã—ã¦3å›å†å¸°å‡¦ç†ã‚’è¡Œã†å ´åˆã€0.8 x 0.8 x 0.8 = 0.512ã¨ãªã‚‹ã®ã§ãŠã‚ˆãç²¾åº¦ãŒ50%ç¨‹åº¦ã«è½ã¡ã¾ã™ã€‚
ãªã®ã§ã€ã“ã®éƒ¨åˆ†ã¯ã¾ã äººã®æ‰‹ãŒå¿…è¦ã ãªã¨æ„Ÿã˜ã¾ã—ãŸã€‚

# æœ€å¾Œã«
ã“ã“ã¾ã§èª­ã‚“ã§ä¸‹ã•ã‚Šã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚
ä½•ã‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚„æ„Ÿæƒ³ç­‰ã‚’é ‚ã‘ã¾ã™ã¨å¹¸ã„ã§ã™ã€‚

# é–¢é€£URL
https://github.com/yantera/whisper-and-chatgpt
https://platform.openai.com/docs/api-reference
https://github.com/newspicks/learn-chatgpt-api